# ğŸ§  Technical Q&A Tool with Ollama (llama3.2)

This is a simple command-line Python tool that uses the [Ollama](https://ollama.com) CLI with the `llama3.2` model to explain technical code snippets or questions in a clear and beginner-friendly way.

---

## ğŸš€ Features

- Ask **technical programming questions** directly in the terminal  
- Uses the `llama3.2` model via `ollama run`  
- Automatically formats your prompt to get clean and understandable explanations  
- Gracefully handles errors from the CLI

---

## ğŸ§© Example Use Case

```bash
$ python ask_llama.py
ğŸ” Technical Question Explainer using llama3.2
Type 'exit' to quit.

â“ Your technical question:
Please explain what this code does and why:
yield from {book.get("author") for book in books if book.get("author")}
``` 
ğŸ’¡ Explanation:
[ model response here... ]
---

## âš™ï¸ Requirements

- Python 3.7+
- Ollama CLI installed
- `llama3.2` model already pulled via:

```bash
ollama pull llama3.2
```

## ğŸ“¦ How to Run
Make sure Ollama CLI is installed and set up correctly.

Clone this repository:
git clone https://github.com/MinaZarifi2023/Technical-Q-A-Tool-with-Ollama.git
cd Technical-Q-A-Tool-with-Ollama




